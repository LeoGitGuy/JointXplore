{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 480)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Data\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "text = \"How many cats are there?\"\n",
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Model\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "# prepare inputs\n",
    "encoding = processor(image, text, return_tensors=\"pt\")\n",
    "# Initializing Dict for storing activation values\n",
    "activations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a hook\n",
    "def create_hook(name, out):\n",
    "  #print(name)\n",
    "  def hook(module, in_tensor, out_tensor):\n",
    "      out[name] = out_tensor\n",
    "  return hook\n",
    "\n",
    "# Loop through all layers of the model and choose the ones with an activaton function to register a hook\n",
    "def get_all_activation_layers(net):\n",
    "  for name, layer in net._modules.items():\n",
    "    if name == \"vilt\":\n",
    "      l1 = list(list(layer._modules.items())[1][1]._modules.items())[0][1]\n",
    "      if isinstance(l1, nn.ModuleList):\n",
    "        for i in range(len(l1)):\n",
    "          n, l2 = list(list(l1[i]._modules.items())[1][1]._modules.items())[1]\n",
    "          name_list = n + \"_\" + str(i)\n",
    "          l2.register_forward_hook(create_hook(name_list, activations))\n",
    "      n3, l3 = list(list(layer._modules.items())[3][1]._modules.items())[1]\n",
    "      l3.register_forward_hook(create_hook(n3, activations))\n",
    "    else:\n",
    "      n4, l4 = list(layer._modules.items())[2]\n",
    "      l4.register_forward_hook(create_hook(n4, activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate_act_fn_0\n",
      "intermediate_act_fn_1\n",
      "intermediate_act_fn_2\n",
      "intermediate_act_fn_3\n",
      "intermediate_act_fn_4\n",
      "intermediate_act_fn_5\n",
      "intermediate_act_fn_6\n",
      "intermediate_act_fn_7\n",
      "intermediate_act_fn_8\n",
      "intermediate_act_fn_9\n",
      "intermediate_act_fn_10\n",
      "intermediate_act_fn_11\n",
      "activation\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "get_all_activation_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model\n",
    "outputs = model(**encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "999ea782e2d719ec62688e738a2ff20f2535cd73f1388dd13a2d835295a4fc1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
